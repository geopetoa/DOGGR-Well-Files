{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import bs4 as bs\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF = \".PDF\"\n",
    "TIF = \".tif\"\n",
    "pdf = \".pdf\"\n",
    "tiff = \".tiff\"\n",
    "link_list = []\n",
    "file_types = [\".PDF\", \".tif\", \".pdf\", \".tiff\"]\n",
    "with open(\"results.csv\", 'r') as file:\n",
    "    welllist = csv.reader(file)    \n",
    "    next(welllist)\n",
    "    for line in welllist:\n",
    "        api = line[0]\n",
    "    #read source code from the link\n",
    "        sauce = urllib.request.urlopen('https://secure.conservation.ca.gov/WellSearch/Details?api='+str(api[2:])).read()\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "            \n",
    "        for url in soup.find_all('a'): # Finds all links\n",
    "            if PDF in str(url): # If the link ends in .PDF\n",
    "                link_list.append(url.get('href'))  #print(link_list)\n",
    "        for url in soup.find_all('a'): # Finds all links\n",
    "            if TIF in str(url): # If the link ends in .tif\n",
    "                link_list.append(url.get('href'))  #print(link_list)\n",
    "\n",
    "        for url in soup.find_all('a'): # Finds all links\n",
    "            if pdf in str(url): # If the link ends in .pdf\n",
    "                link_list.append(url.get('href'))  #print(link_list)\n",
    "\n",
    "        for url in soup.find_all('a'): # Finds all links\n",
    "            if tiff in str(url): # If the link ends in .tiff\n",
    "                link_list.append(url.get('href'))  #print(link_list)\n",
    "        \n",
    "        dirname = \"__\".join((line[0], line[1], line[2], line[3], line[4], line[6]))\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "            for u in link_list:\n",
    "                filename = u.rsplit('/', 1)[-1]  # Split on the rightmost / and take everything on the right side of that\n",
    "                if not os.path.isfile(filename):\n",
    "                    fullfilename = os.path.join(str(dirname), filename)\n",
    "                    urllib.request.urlretrieve(u, fullfilename)\n",
    "                \n",
    "        del link_list[:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}